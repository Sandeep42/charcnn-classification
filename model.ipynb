{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes, num_chars=70, max_seq_length=1014, kernel_sizes= [7,7,3,3,3,3], \n",
    "                 channel_size=256, pool_size=3):\n",
    "        \n",
    "        super(CharCNN, self).__init__()\n",
    "        \n",
    "        self.num_chars = num_chars\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.n_classes = n_classes\n",
    "        self.pool_size = pool_size\n",
    "        self.final_linear_len = (max_seq_length - 96)/ 27\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(num_chars, channel_size, kernel_sizes[0])\n",
    "        self.conv2 = nn.Conv1d(channel_size, channel_size, kernel_sizes[1])\n",
    "        self.conv3 = nn.Conv1d(channel_size, channel_size, kernel_sizes[2])\n",
    "        self.conv4 = nn.Conv1d(channel_size, channel_size, kernel_sizes[3])\n",
    "        self.conv5 = nn.Conv1d(channel_size, channel_size, kernel_sizes[4])\n",
    "        self.conv6 = nn.Conv1d(channel_size, channel_size, kernel_sizes[5])\n",
    "        \n",
    "        self.pool1 = nn.MaxPool1d(pool_size)\n",
    "        self.pool2 = nn.MaxPool1d(pool_size)\n",
    "        self.pool3 = nn.MaxPool1d(pool_size)\n",
    "        \n",
    "        self.FC1 = nn.Linear(channel_size * self.final_linear_len, 1024)\n",
    "        self.FC2 = nn.Linear(1024, 1024)\n",
    "        self.final_layer = nn.Linear(1024, n_classes)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                m.weight.data.normal_(0, 0.05)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.05)\n",
    "\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool3(F.relu(self.conv6(x)))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.FC1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.FC2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.final_layer(x)\n",
    "        return F.log_softmax(x)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charcnn = CharCNN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = Variable(torch.randn(64,70,1014))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the forward pass with a random input with batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 7 \n",
       " -68.8173 -104.9899  -25.6022  -42.4737  -80.5405   -0.0011  -27.8097   -6.8594\n",
       "  -0.0000  -50.6404 -154.2055 -105.0202  -62.1325  -54.2097  -39.9622  -66.6271\n",
       "   0.0000 -206.8687 -120.9110 -179.8722 -103.0993  -99.9894 -118.5074 -220.0174\n",
       "-157.6653 -149.9798    0.0000 -221.4961 -100.3018 -165.9884 -176.3581 -107.7630\n",
       " -88.3535  -28.9064 -125.5320 -158.0676 -212.1708  -51.4926  -39.0871 -130.1813\n",
       "-105.3856  -15.5726  -39.3309 -199.9827 -194.3597  -26.0501   -0.0013 -149.4773\n",
       "  -0.0000  -66.4504  -52.4241 -103.8333 -116.5250  -18.8425  -65.4385 -135.8221\n",
       " -29.3479 -120.5390  -97.0079 -122.2001  -43.9130 -106.3288   -0.0000  -75.2879\n",
       " -98.2197  -36.9157 -151.0684  -96.4283 -135.4412   -0.0001 -168.7530 -123.6483\n",
       " -30.2257 -111.6708  -35.5697  -57.5128 -168.4377   -0.0000 -101.8533  -84.4177\n",
       "   0.0000 -201.5231 -129.1893 -180.1489 -181.6742 -201.0459 -197.9904 -264.5238\n",
       " -67.5501 -245.7548    0.0000 -181.5725 -145.6481  -92.1788 -105.0201 -217.6792\n",
       "  -0.0000  -81.1011  -30.8596 -180.3558  -45.1160  -57.5606  -42.4481  -86.3800\n",
       " -79.1100 -156.7773  -57.7577 -144.4273 -207.1620    0.0000 -187.3343 -192.6416\n",
       " -81.1623  -68.5533   -0.0000 -129.4651 -144.0930  -74.3662  -21.8971 -119.7645\n",
       "-241.9916 -172.3968 -197.7916 -159.3696 -283.1917 -120.7621 -263.4062 -203.9391\n",
       "  -2.5634   -0.0802 -165.6797 -103.7071 -183.4596  -21.4561  -67.9188  -74.2713\n",
       "  -0.0000 -170.7248  -32.1807 -140.4843 -103.6238  -79.7975  -87.9983  -94.0577\n",
       " -21.1335  -74.8940  -52.8148  -87.1683   -0.2869  -22.1492  -93.3584 -114.1312\n",
       "  -0.0000  -37.5165 -100.3968 -179.2162 -150.2913 -128.5952  -67.6132 -130.9699\n",
       "-125.4432  -99.9208  -38.6501 -163.4287  -79.8735 -169.4685 -143.9578 -182.1016\n",
       "-131.4290  -86.9290  -28.7756  -59.9265 -173.6066   -0.0000 -123.4124  -79.0864\n",
       " -39.3260  -29.7603  -52.6677  -87.7473  -79.5737  -83.1716   -0.0000  -19.4680\n",
       " -80.5201 -114.7817  -57.4516 -220.2902 -121.1491  -33.6728   -0.0013  -18.6344\n",
       " -19.5000 -244.9154 -155.2666 -171.0188 -166.0719  -99.4766   -1.9792 -146.2566\n",
       "-176.6326 -242.1291    0.0000 -213.5897 -206.7064 -236.9817  -78.3761 -192.9847\n",
       "-118.8757 -105.3157 -147.1585 -158.0445 -138.7524  -48.8618   -0.0000  -11.8912\n",
       " -87.7215 -137.1784  -49.0398 -247.3157 -149.0837  -56.9353   -0.0000 -152.8246\n",
       "-123.8831 -211.5652    0.0000 -134.1701 -199.0695  -62.9285  -78.3247 -154.1045\n",
       "-112.7016    0.0000  -41.3774 -125.8147  -81.1768 -107.3784 -149.8358 -220.2496\n",
       "  -0.0000  -48.3316 -118.1960  -84.3643  -68.9003  -79.7819  -65.8806  -81.1458\n",
       " -87.3779 -121.0383   -0.0000  -95.0349  -53.1222  -49.5550 -134.5230 -108.2247\n",
       " -54.5950  -87.4629  -33.7948 -197.2525  -34.4155   -2.2546 -104.1983   -0.1108\n",
       "   0.0000 -177.3621 -200.0201 -282.1729 -144.6220 -175.7319 -151.4137 -246.3381\n",
       " -19.9274  -60.5431 -170.0927 -203.1455 -147.2823 -105.2933 -203.2848 -104.2381\n",
       " -64.5685 -220.0670 -159.1317 -238.6254  -59.9715 -125.9229  -78.1653 -277.4757\n",
       "   0.0000  -49.6369 -118.7752 -169.0358 -115.2570  -82.8935  -88.7794 -209.6442\n",
       " -29.1367  -77.7016 -100.8906 -196.0210 -150.5699 -115.5728 -120.4655 -215.0314\n",
       " -44.1923  -23.6118  -53.8898 -102.4082  -32.0221  -82.3505   -0.0002 -112.1530\n",
       "-143.8884 -136.0985 -182.7920 -172.8838  -86.3320 -159.2916 -200.6031 -223.8078\n",
       " -89.0551 -209.0644 -100.8706 -159.8185 -167.3424 -149.6633  -72.5558 -239.1385\n",
       "  -0.0781 -226.9816  -76.0982 -186.0274 -106.3519 -121.5099 -201.7002 -220.3889\n",
       " -53.0896  -30.4928 -130.6778 -224.2788  -49.5128   -0.0000 -175.4657 -167.9073\n",
       "-120.3590 -183.7915 -144.5544 -220.8059  -83.4425    0.0000 -192.8364 -102.8046\n",
       "   0.0000 -147.9524 -171.5577 -224.6074 -164.4633 -184.8014  -67.1530 -228.6493\n",
       " -50.2268  -87.6297  -47.0300  -96.3071 -185.0663  -16.5821   -0.0000 -125.8435\n",
       " -15.0591  -89.5069  -29.6053  -42.2971   -7.2221  -75.8255 -107.5377  -75.5554\n",
       "-111.4380  -85.4442  -38.9312  -87.0209 -160.3763   -1.6101 -125.2822 -100.2201\n",
       " -73.5610 -144.2203 -143.4264 -179.4580 -202.9760 -168.2868 -225.0374 -178.1856\n",
       "  -0.0019  -66.9765  -76.4347  -33.2310  -88.1170  -65.5262   -6.2761  -79.4195\n",
       " -86.0549 -168.4154  -51.1343 -252.9492 -105.7770 -188.8695  -52.2671 -187.3676\n",
       " -26.4698   -0.0000  -91.0965 -107.9199  -98.3427 -149.4097  -60.3735 -176.0012\n",
       "-248.1515 -189.6756    0.0000 -278.0506 -121.2959 -229.4186 -186.7424 -120.4253\n",
       " -82.2568  -53.9747  -93.7732 -193.5364 -135.9288  -55.7915 -130.8523 -182.6979\n",
       " -21.9442  -63.2648   -5.7679  -58.3652  -37.3862   -0.0031  -13.6793  -51.2350\n",
       " -56.3395  -81.5328  -66.8085 -172.8094  -72.9654  -62.3211  -21.4828 -138.5447\n",
       "   0.0000 -144.6543 -230.2849 -208.4351 -229.8692 -200.8611 -170.6808 -181.4461\n",
       " -50.2977 -216.3080 -164.4406 -140.8338 -101.9751  -93.9838  -90.2143 -112.1621\n",
       "-107.4609 -162.0667  -19.9131 -121.7229 -123.2064   -0.0000  -34.7355 -111.2599\n",
       " -19.7504  -85.7943  -76.8633 -112.3054  -35.8250   -0.0000  -15.2952 -155.4672\n",
       " -69.9133  -77.0434   -0.0000 -167.1093  -32.1620  -48.4337 -120.3576  -81.2687\n",
       " -45.5657 -156.1588 -113.2423 -157.5904 -168.2529    0.0000 -133.9112 -153.2604\n",
       " -12.8009   -0.0000  -57.9965 -171.7238 -183.8006 -148.6290  -33.4911 -170.6558\n",
       "   0.0000 -105.3370 -116.6963 -116.7686 -174.2672  -74.3711 -285.7481 -103.7069\n",
       "\n",
       "Columns 8 to 9 \n",
       " -39.8314  -18.4798\n",
       " -29.3831  -80.6510\n",
       "-101.7685 -130.1261\n",
       "-118.8489 -142.0450\n",
       "  -0.0000  -36.4331\n",
       "  -6.6188 -185.3105\n",
       " -25.8148 -152.1608\n",
       " -68.3317  -98.8225\n",
       "  -9.7950 -131.0657\n",
       "-118.9559 -285.4745\n",
       " -88.4632 -107.9844\n",
       " -37.4916 -149.4696\n",
       " -55.3631 -176.5209\n",
       "-129.9384 -192.0111\n",
       " -77.4971  -83.4593\n",
       "   0.0000 -235.3990\n",
       "-112.1108  -84.2729\n",
       " -83.2852 -118.0158\n",
       "  -1.3888 -120.4555\n",
       " -31.7415  -99.2558\n",
       "   0.0000 -107.0566\n",
       "-146.9635  -18.4153\n",
       " -55.8170  -38.3893\n",
       "  -6.6169 -124.5529\n",
       "  -0.1487  -55.5921\n",
       "-260.2979 -206.8203\n",
       " -16.3523 -188.8620\n",
       " -26.6255 -139.5622\n",
       "-192.5675 -220.0233\n",
       " -60.3802 -211.6065\n",
       " -18.7812  -54.1284\n",
       " -16.7845  -67.1030\n",
       " -40.4764 -150.7974\n",
       "-117.2077 -188.6187\n",
       "  -0.0000 -162.5164\n",
       "   0.0000 -171.5925\n",
       " -66.1102  -76.3133\n",
       "  -0.0000 -126.1768\n",
       "  -8.3292  -64.8397\n",
       " -10.1143   -0.0000\n",
       " -88.2705    0.0000\n",
       "  -2.5889 -217.8843\n",
       " -50.0281 -110.1095\n",
       " -42.8533 -213.4348\n",
       "-136.2368 -163.0637\n",
       " -28.5609  -98.3162\n",
       " -44.0496   -0.0007\n",
       "  -0.2230 -149.2330\n",
       "   0.0000 -236.0258\n",
       " -67.7516  -60.4643\n",
       "   0.0000 -191.0766\n",
       " -57.3360  -68.3900\n",
       "-181.4191 -172.5490\n",
       "   0.0000 -101.8647\n",
       "-107.8986  -17.4150\n",
       "  -0.0000  -78.0255\n",
       " -42.1362 -263.7188\n",
       "   0.0000 -114.4080\n",
       " -81.3278 -230.2046\n",
       " -22.9643 -120.7678\n",
       " -85.7061 -213.7202\n",
       " -76.1001 -118.5344\n",
       " -60.4292  -57.0830\n",
       "-140.6853 -151.9689\n",
       "[torch.FloatTensor of size 64x10]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charcnn(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
